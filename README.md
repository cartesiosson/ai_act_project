<p align="center">
  <img src="docs/seramis-logo.svg" alt="SERAMIS Logo" width="200"/>
</p>

<h1 align="center">SERAMIS v1.0</h1>

<h3 align="center">Semantic Reasoning and AI Management Intelligent System</h3>

<p align="center">
  <strong>Plataforma de evaluaciÃ³n semÃ¡ntica automatizada para el cumplimiento del Reglamento Europeo de Inteligencia Artificial (EU AI Act) </strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/version-1.1.0-blue.svg" alt="Version"/>
  <img src="https://img.shields.io/badge/EU%20AI%20Act-Compliant-green.svg" alt="EU AI Act"/>
  <img src="https://img.shields.io/badge/ontology-v0.37.5-purple.svg" alt="Ontology"/>
  <img src="https://img.shields.io/badge/DPV-2.2-orange.svg" alt="DPV 2.2"/>
  <img src="https://img.shields.io/badge/ELI-EUR--Lex-blue.svg" alt="ELI"/>
  <img src="https://img.shields.io/badge/license-CC%20BY%204.0-lightgrey.svg" alt="License"/>
</p>

---

## Trabajo Fin de MÃ¡ster - UNIR

<p align="center">
  <img src="docs/logo-unir.png" alt="UNIR Logo" width="250"/>
</p>

Este proyecto ha sido desarrollado como **Trabajo Fin de MÃ¡ster** del programa de **MÃ¡ster en Inteligencia Artificial** de la **Universidad Internacional de La Rioja (UNIR)**.

### Equipo de Desarrollo

| Rol | Nombre |
|-----|--------|
| **Autores** | David FernÃ¡ndez GonzÃ¡lez, Dr. Mariano Ortega de Mues |
| **Directora** | Dra. Xiomara Patricia Blanco Valencia |
| **Co-Director** | Dr. Sergio Castillo |

### Agradecimientos

Este proyecto utiliza datos del **[AIAAIC Repository](https://www.aiaaic.org/aiaaic-repository)** (AI, Algorithmic, and Automation Incidents and Controversies), una base de datos independiente que documenta incidentes de IA a nivel mundial. Agradecemos a **Charlie Pownall** y al equipo de AIAAIC por este recurso invaluable.

La ontologÃ­a SERAMIS incorpora compatibilidad con **[AIRO (AI Risk Ontology)](https://w3id.org/airo)**, desarrollada por **Delaram Golpayegani** et al. en el ADAPT Centre, Dublin City University. Agradecemos al equipo de AIRO por su trabajo en la estandarizaciÃ³n de conceptos de stakeholders para sistemas de IA.

La integraciÃ³n con **[W3C Data Privacy Vocabulary (DPV) 2.2](https://w3c.github.io/dpv/)** permite mapear requisitos del EU AI Act a medidas tÃ©cnicas y organizativas estÃ¡ndar, facilitando la generaciÃ³n de planes de evidencia para cumplimiento normativo.

La integraciÃ³n con **[European Legislation Identifier (ELI)](https://eur-lex.europa.eu/eli-register/about.html)** proporciona URIs persistentes y desreferenciables para referenciar artÃ­culos especÃ­ficos del AI Act en EUR-Lex, garantizando la interoperabilidad con el ecosistema legislativo europeo.

Este software fue parcialmente desarrollado empleando **Claude Sonnet** (Anthropic), asistente de IA utilizado para acelerar el desarrollo de cÃ³digo, documentaciÃ³n y diseÃ±o arquitectÃ³nico.

---

## Ãndice

- [DescripciÃ³n](#descripciÃ³n)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [InstalaciÃ³n](#instalaciÃ³n)
- [MÃ³dulos del Frontend](#mÃ³dulos-del-frontend)
- [Agente Forense](#agente-forense)
- [OntologÃ­a](#ontologÃ­a)
  - [IntegraciÃ³n AIRO](#integraciÃ³n-airo-ai-risk-ontology)
  - [IntegraciÃ³n DPV](#integraciÃ³n-dpv-data-privacy-vocabulary)
  - [Razonamiento sobre Affected Persons](#razonamiento-sobre-affected-persons-art-86)
  - [Mappings Multi-Framework](#mappings-multi-framework)
- [Mecanismos de Inferencia](#mecanismos-de-inferencia)
- [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [API Reference](#api-reference)
- [Referencias](#referencias)
- [Licencia](#licencia)

---

## DescripciÃ³n

SERAMIS implementa un **sistema de evaluaciÃ³n semÃ¡ntica automatizada** para sistemas de IA regulados por el EU AI Act. Combina una ontologÃ­a formal OWL (v0.37.5) con reglas de inferencia SWRL para derivar automÃ¡ticamente requisitos de cumplimiento, evaluaciones de riesgo y obligaciones regulatorias.

### CaracterÃ­sticas Principales

- **Razonamiento SemÃ¡ntico HÃ­brido** (SWRL + SHACL) para clasificaciÃ³n automÃ¡tica de riesgo
- **AnÃ¡lisis Forense Post-Incidente** con extracciÃ³n LLM de narrativas de incidentes
- **Cumplimiento Multi-Framework**: EU AI Act + ISO 42001 + NIST AI RMF + DPV
- **Evidence Planner**: GeneraciÃ³n automÃ¡tica de planes de evidencia basados en gaps de cumplimiento
- **DPV Browser**: Explorador interactivo del W3C Data Privacy Vocabulary con taxonomÃ­as de riesgos, medidas y conceptos del AI Act
- **VisualizaciÃ³n 3D** interactiva del grafo de conocimiento
- **Persistencia Dual**: MongoDB para documentos + Apache Jena Fuseki para RDF/SPARQL
- **Servidor MCP** (Model Context Protocol) para integraciÃ³n con agentes de IA

---

## Arquitectura del Sistema

```mermaid
flowchart TB
    subgraph Frontend["React Frontend :5173"]
        SP[AI Systems DB<br/>Registration & Classification]
        GV[AI Knowledge Graph<br/>3D Force Graph]
        RP[AI Symbolic Reasoning<br/>SWRL Inference]
        FA[Forensic AI Agent<br/>AIAAIC Analysis]
        DP[DPV Browser<br/>W3C DPV Explorer]
    end

    subgraph Backend["FastAPI Backend :8000"]
        CL[Core Logic<br/>Derivation & Requirements]
        RT[Routers<br/>/systems /reason /fuseki]
    end

    subgraph Forensic["Forensic Agent :8002"]
        AE[Analysis Engine<br/>LLM Extraction]
        CL2[EU AI Act Classification<br/>ISO 42001 / NIST Mappings]
        EP[Evidence Planner<br/>DPV Integration]
    end

    subgraph Data["Data Layer"]
        MG[(MongoDB :27017<br/>Documents)]
        FK[(Fuseki :3030<br/>RDF/SPARQL)]
    end

    subgraph Reasoner["Reasoner Service :8001"]
        RS[SWRL Inference<br/>OwlReady2]
    end

    subgraph MCPServer["MCP Server :8080"]
        MCP[FastMCP 2.0<br/>SPARQL Tools]
    end

    subgraph LLM["LLM Runtime :11434"]
        OL[Ollama<br/>Llama 3.2]
    end

    SP & GV & RP -->|HTTP/REST| Backend
    DP -->|HTTP/REST| Backend
    FA -->|HTTP/REST| Forensic
    Backend -->|MongoDB Protocol| MG
    Backend -->|HTTP/SPARQL| FK
    Backend -->|HTTP/REST| RS
    RS -->|HTTP/SPARQL| FK
    Forensic -->|HTTP/JSON| OL
    Forensic -->|SSE/JSON-RPC| MCP
    MCP -->|HTTP/SPARQL| FK
    Forensic -->|MongoDB Protocol| MG
    Forensic -->|HTTP/SPARQL UPDATE| FK
    AE --> CL2

    style Frontend fill:#3b82f6,color:#fff
    style Backend fill:#10b981,color:#fff
    style Forensic fill:#8b5cf6,color:#fff
    style Data fill:#f59e0b,color:#fff
    style Reasoner fill:#ef4444,color:#fff
    style MCPServer fill:#ef4444,color:#fff
    style LLM fill:#ef4444,color:#fff
```

---

## InstalaciÃ³n

### Prerrequisitos

- **Docker** & **Docker Compose**
- **Git**
- **Ollama** (para el agente forense LLM - usa llama3.2:3b)

### Inicio RÃ¡pido

```bash
# 1. Clonar repositorio
git clone https://github.com/[usuario]/seramis.git
cd seramis

# 2. Iniciar todos los servicios
docker-compose up -d

# 3. Verificar despliegue
docker-compose ps
```

### Puntos de Acceso

| Servicio | URL | DescripciÃ³n |
|----------|-----|-------------|
| **Frontend** | http://localhost:5173 | Interfaz web principal |
| **AI Systems DB** | http://localhost:5173/systems | Base de datos de sistemas de IA |
| **AI Knowledge Graph** | http://localhost:5173/graph | VisualizaciÃ³n 3D de la ontologÃ­a |
| **AI Symbolic Reasoning** | http://localhost:5173/reasoning | Razonamiento SWRL |
| **Forensic AI Agent** | http://localhost:5173/forensic | AnÃ¡lisis de incidentes AIAAIC |
| **DPV Browser** | http://localhost:5173/dpv | Explorador Data Privacy Vocabulary |
| **API Docs** | http://localhost:8000/docs | DocumentaciÃ³n API (Swagger) |
| **API Forense** | http://localhost:8002/docs | DocumentaciÃ³n API forense |
| **SPARQL Endpoint** | http://localhost:3030 | Consultas RDF/SPARQL |
| **MCP Server** | http://localhost:8080/mcp | Model Context Protocol |

---

## MÃ³dulos del Frontend

El frontend de SERAMIS proporciona una interfaz web completa para la gestiÃ³n y anÃ¡lisis de sistemas de IA:

| MÃ³dulo | Ruta | DescripciÃ³n |
|--------|------|-------------|
| **Dashboard** | `/` | Panel principal con mÃ©tricas y resumen del sistema |
| **AI Systems DB** | `/systems` | Base de datos de sistemas de IA con formulario de registro, clasificaciÃ³n de riesgo EU AI Act y gestiÃ³n de requisitos |
| **AI Knowledge Graph** | `/graph` | VisualizaciÃ³n 3D interactiva del grafo de conocimiento usando Force Graph y Three.js |
| **AI Symbolic Reasoning** | `/reasoning` | Interfaz para ejecutar razonamiento SWRL sobre sistemas registrados |
| **Forensic AI Agent** | `/forensic` | AnÃ¡lisis forense post-incidente de sistemas de IA usando datos AIAAIC |
| **DPV Browser** | `/dpv` | Explorador interactivo del W3C Data Privacy Vocabulary 2.2 |
| **Ontology Docs** | `/ontology` | DocumentaciÃ³n de la ontologÃ­a SERAMIS |

### DPV Browser

El **DPV Browser** (`/dpv`) es un explorador interactivo del [W3C Data Privacy Vocabulary (DPV) 2.2](https://w3c.github.io/dpv/) que permite navegar las taxonomÃ­as de:

- **Riesgos de IA** (`dpv-ai:Risk`): TaxonomÃ­a de riesgos asociados a sistemas de IA
- **Medidas TÃ©cnicas y Organizativas** (`dpv:TechnicalMeasure`, `dpv:OrganisationalMeasure`): CatÃ¡logo de medidas de cumplimiento
- **Conceptos AI Act** (`dpv-legal-eu-aiact:`): TÃ©rminos especÃ­ficos del EU AI Act
- **PropÃ³sitos y Bases Legales**: TaxonomÃ­as de procesamiento de datos

Esta herramienta facilita la consulta y comprensiÃ³n del vocabulario DPV para la generaciÃ³n de planes de evidencia y la evaluaciÃ³n de cumplimiento.

---

## Agente Forense

El **Agente Forense** es un microservicio potenciado por LLM para anÃ¡lisis de cumplimiento post-incidente. Extrae informaciÃ³n estructurada de narrativas de incidentes y evalÃºa el cumplimiento contra mÃºltiples frameworks.

ğŸ“– **DocumentaciÃ³n completa:** [`forensic_agent/README.md`](forensic_agent/README.md)

### Fuente de Datos: AIAAIC Repository

El agente utiliza datos del **AI, Algorithmic, and Automation Incidents and Controversies (AIAAIC) Repository**, una base de datos independiente que documenta incidentes relacionados con sistemas de IA a nivel mundial.

ğŸ”— **AIAAIC Repository:** https://www.aiaaic.org/aiaaic-repository

### CaracterÃ­sticas

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **ExtracciÃ³n LLM** | Usa Ollama (llama3.2:3b) o Anthropic para extraer datos estructurados |
| **AnÃ¡lisis Multi-Framework** | EU AI Act + ISO 42001 (15 mappings) + NIST AI RMF (18 mappings) + DPV 2.2 |
| **ClasificaciÃ³n de Riesgo** | CategorizaciÃ³n automÃ¡tica segÃºn 8 categorÃ­as del Anexo III + GPAI |
| **DetecciÃ³n de Brechas** | Identifica requisitos faltantes y calcula ratio de cumplimiento |
| **Evidence Planner** | Genera planes de evidencia con 14 requisitos y ~40 items de evidencia |
| **Persistencia Dual** | Guarda en MongoDB + Fuseki RDF para consultas semÃ¡nticas |

### Ejemplo de AnÃ¡lisis

```bash
curl -X POST http://localhost:8002/forensic/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "narrative": "Sistema de reconocimiento facial utilizado por fuerzas policiales para identificar manifestantes. El sistema mostrÃ³ sesgo significativo contra minorÃ­as.",
    "source": "AIAAIC Repository",
    "metadata": {
      "aiaaic_id": "AIAAIC0042",
      "headline": "Sesgo en reconocimiento facial policial"
    }
  }'
```

---

## OntologÃ­a

### VersiÃ³n: 0.37.4

| Propiedad | Valor |
|-----------|-------|
| **Namespace** | `http://ai-act.eu/ai#` |
| **Formato** | Turtle (.ttl) |
| **Clases** | 60+ |
| **Propiedades** | 50+ |
| **Individuos** | 120+ |
| **Tripletas** | ~2,000 |

### Cobertura Regulatoria

- EU AI Act Anexo III (8/8 categorÃ­as de alto riesgo)
- **ArtÃ­culo 5** (PrÃ¡cticas Prohibidas - Riesgo Inaceptable)
- ArtÃ­culos 51-55 (requisitos GPAI)
- TaxonomÃ­a de algoritmos (Anexo I)
- Framework de gobernanza de datos
- Shapes SHACL de validaciÃ³n
- Reglas de inferencia SWRL

### IntegraciÃ³n AIRO (AI Risk Ontology)

La ontologÃ­a SERAMIS v0.37.2 incorpora compatibilidad con **AIRO** para la gestiÃ³n de stakeholders segÃºn el EU AI Act:

| Propiedad SERAMIS | Clase AIRO | ArtÃ­culo EU AI Act |
|-------------------|------------|-------------------|
| `ai:hasProvider` | `airo:AIProvider` | Art. 3.3 |
| `ai:hasDeployer` | `airo:AIDeployer` | Art. 3.4 |
| `ai:hasDeveloper` | `airo:AIDeveloper` | - |
| `ai:hasUser` | `airo:AIUser` | - |
| `ai:hasSubject` | `airo:AISubject` | Art. 86 (Affected Person) |
| `ai:hasOversightBody` | `airo:Regulator` | Art. 70 |

Esta integraciÃ³n permite:
- **Trazabilidad de responsabilidad**: Identificar claramente quiÃ©n desarrolla, despliega y opera cada sistema
- **AnÃ¡lisis forense mejorado**: El Agente Forense extrae deployer/developer de incidentes AIAAIC
- **Interoperabilidad**: Compatible con otras ontologÃ­as que usen AIRO
- **Razonamiento sobre Affected Persons**: Inferencia automÃ¡tica de requisitos basados en personas afectadas

### IntegraciÃ³n DPV (Data Privacy Vocabulary)

SERAMIS v1.1.0 integra el **[W3C Data Privacy Vocabulary (DPV) 2.2](https://w3c.github.io/dpv/)** para la generaciÃ³n de planes de evidencia de cumplimiento.

| ExtensiÃ³n DPV | PropÃ³sito | Uso en SERAMIS |
|---------------|-----------|----------------|
| **dpv:core** | Medidas tÃ©cnicas y organizativas | Mapeo de requisitos a medidas |
| **dpv:ai** | Sistemas de IA, capacidades, riesgos | ClasificaciÃ³n de sistemas |
| **dpv:risk** | GestiÃ³n de riesgos | EvaluaciÃ³n de gaps |
| **dpv:legal/eu/aiact** | Conceptos especÃ­ficos AI Act | Equivalencias semÃ¡nticas |

#### Tipos de Evidencia Definidos

El mÃ³dulo `dpv-integration.ttl` define 6 tipos de evidencia:

| Tipo | DescripciÃ³n | Ejemplo |
|------|-------------|---------|
| `PolicyEvidence` | PolÃ­ticas y procedimientos | Human Oversight Policy |
| `TechnicalEvidence` | DocumentaciÃ³n tÃ©cnica | Model Card, System Architecture |
| `AuditEvidence` | Logs, tests, auditorÃ­as | Bias Audit Report |
| `TrainingEvidence` | Registros de formaciÃ³n | Operator Training Records |
| `AssessmentEvidence` | Evaluaciones de impacto | FRIA Report, DPIA |
| `ContractualEvidence` | Contratos y acuerdos | Data Processing Agreement |

#### Mappings Requisito â†’ Medida DPV

```turtle
ai:HumanOversightRequirement
    ai:mapsToDPVMeasure dpv:HumanInvolvement ;
    ai:requiresEvidence ai:HumanOversightPolicyEvidence,
                        ai:OverrideDecisionLogEvidence .

ai:FundamentalRightsAssessmentRequirement
    ai:mapsToDPVMeasure dpv:ImpactAssessment ;
    ai:requiresEvidence ai:FRIAReportEvidence .
```

### Razonamiento sobre Affected Persons (Art. 86)

El reasoner implementa **4 reglas de inferencia** basadas en la identificaciÃ³n de "Affected Persons" (personas afectadas por decisiones del sistema de IA):

| Regla | ArtÃ­culo | CondiciÃ³n | Inferencia |
|-------|----------|-----------|------------|
| **7** | Art. 86 | `hasSubject` + `HighRisk` | `requiresExplainability = true` |
| **8** | Art. 27 | Affected person en grupo vulnerable | `requiresFundamentalRightsAssessment = true` |
| **9** | Art. 26 | PropÃ³sito de empleo + affected persons | `requiresAffectedPersonNotification = true` |
| **10** | Art. 5 | BiomÃ©trico + espacio pÃºblico + affected persons | `requiresProhibitionReview = true` |

**Grupos vulnerables detectados automÃ¡ticamente:**
- Menores (Minor/Child)
- Personas mayores (Elderly)
- Personas con discapacidad (Disabled)
- Migrantes y solicitantes de asilo (Migrant/Asylum)

**Propiedades de inferencia aÃ±adidas:**
- `ai:requiresExplainability` - Requiere explicabilidad Art. 86
- `ai:requiresFundamentalRightsAssessment` - Requiere FRIA Art. 27
- `ai:requiresAffectedPersonNotification` - Requiere notificaciÃ³n Art. 26
- `ai:requiresProhibitionReview` - Requiere revisiÃ³n prohibiciones Art. 5

**Requisitos de cumplimiento inferidos:**
- `ai:ExplainabilityRequirement`
- `ai:FundamentalRightsImpactAssessment`
- `ai:WorkerNotificationRequirement`
- `ai:Article5ProhibitionReview`

### Mappings Multi-Framework

| Framework | Tipo | Mappings | Confianza |
|-----------|------|----------|-----------|
| **EU AI Act** | RegulaciÃ³n obligatoria | Base | - |
| **ISO 42001** | EstÃ¡ndar de certificaciÃ³n | 15 | 87% HIGH |
| **NIST AI RMF** | GuÃ­a voluntaria | 18 | 100% HIGH |
| **DPV 2.2** | Vocabulario W3C | 14 | - |
| **Total** | Multi-framework | **47+** | **94% HIGH** |

---

## Mecanismos de Inferencia

SERAMIS implementa **tres mecanismos de inferencia** basados en diferentes secciones del EU AI Act para la clasificaciÃ³n automÃ¡tica de sistemas de IA:

### 1. Inferencia por PropÃ³sito + Contexto (Anexo III)

Clasifica sistemas de IA como **Alto Riesgo** basÃ¡ndose en la combinaciÃ³n del propÃ³sito del sistema y su contexto de despliegue, segÃºn las 8 categorÃ­as del Anexo III del EU AI Act.

```mermaid
flowchart LR
    P[PropÃ³sito] --> C1[Criterios PropÃ³sito]
    X[Contexto] --> C2[Criterios Contexto]
    C1 --> U[UniÃ³n de Criterios]
    C2 --> U
    U --> R[Requisitos Anexo III]
    R --> RL[Alto Riesgo]

    style P fill:#3b82f6,color:#fff
    style X fill:#8b5cf6,color:#fff
    style U fill:#f59e0b,color:#fff
    style RL fill:#ef4444,color:#fff
```

**CategorÃ­as cubiertas:**
- BiometrÃ­a e identificaciÃ³n de personas
- GestiÃ³n de infraestructuras crÃ­ticas
- EducaciÃ³n y formaciÃ³n profesional
- Empleo y gestiÃ³n de trabajadores
- Acceso a servicios esenciales (crÃ©dito, seguros)
- AplicaciÃ³n de la ley
- MigraciÃ³n, asilo y control fronterizo
- AdministraciÃ³n de justicia y procesos democrÃ¡ticos

### 2. Inferencia por Experto Humano (ArtÃ­culo 6.3)

Permite que un **experto humano** identifique manualmente **criterios de riesgo adicionales** para sistemas que no son capturados por las reglas automÃ¡ticas de PropÃ³sito + Contexto. Esta evaluaciÃ³n experta complementa la inferencia automÃ¡tica.

En el interfaz **AI Systems DB**, la SecciÃ³n 6 "Expert Evaluation" permite al evaluador:

```
Si experto identifica riesgos no detectados automÃ¡ticamente
   â†’ AÃ±ade criterios manualmente (hasManuallyIdentifiedCriterion)
   â†’ Sistema reclasificado a HighRisk con criterios adicionales
```

**Campos disponibles en el formulario:**
- `hasManuallyIdentifiedCriterion`: Criterios de alto riesgo identificados por el experto
- SelecciÃ³n mÃºltiple de criterios del catÃ¡logo del Anexo III
- Los criterios manuales se combinan con los criterios derivados automÃ¡ticamente

**AplicaciÃ³n del Art. 6.3:**
- Casos residuales no cubiertos por reglas automÃ¡ticas
- Sistemas con riesgo contextual especÃ­fico
- EvaluaciÃ³n caso por caso por experto cualificado

### 3. Inferencia para Modelos GPAI (ArtÃ­culos 51-55)

Clasifica **Modelos de PropÃ³sito General** (GPAI) y detecta aquellos con **Riesgo SistÃ©mico** basÃ¡ndose en capacidad computacional y otros indicadores.

```
Si modelo GPAI tiene FLOPS â‰¥ 10^25
   â†’ Riesgo SistÃ©mico (Art. 51)
   â†’ Requisitos adicionales Arts. 52-55
```

**Criterios de Riesgo SistÃ©mico:**
- Capacidad computacional â‰¥ 10Â²âµ FLOPS de entrenamiento
- Capacidades de alto impacto determinadas por la ComisiÃ³n
- NÃºmero significativo de usuarios registrados

### Resumen de Mecanismos

| Mecanismo | Base Legal | Entrada | Salida |
|-----------|------------|---------|--------|
| **PropÃ³sito + Contexto** | Anexo III | PropÃ³sito, Contexto de despliegue | HighRisk / NotHighRisk + Criterios automÃ¡ticos |
| **Experto Humano** | Art. 6.3 | `hasManuallyIdentifiedCriterion` | Criterios adicionales â†’ HighRisk |
| **GPAI** | Arts. 51-55 | FLOPS, capacidades | SystemicRisk / GPAI estÃ¡ndar |

---

## Stack TecnolÃ³gico

### Backend
- Python 3.11
- FastAPI
- RDFLib (procesamiento RDF/OWL)
- OwlReady2 (razonamiento OWL)
- Motor (MongoDB async)
- FastMCP 2.0 (Model Context Protocol)

### Frontend
- React 19
- TypeScript
- Vite
- TailwindCSS
- react-force-graph-3d (visualizaciÃ³n 3D)
- Three.js (rendering WebGL)

### AI/LLM
- Ollama (runtime LLM local)
- llama3.2:3b (modelo por defecto)

### Infraestructura
- Docker & Docker Compose
- Apache Jena Fuseki
- MongoDB 6
- NGINX

---

## Estructura del Proyecto

```
seramis/
â”œâ”€â”€ backend/                    # FastAPI backend (8000)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ derivation.py
â”‚   â”œâ”€â”€ routers/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ frontend/                   # React + TypeScript UI (5173)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ DashboardPage.tsx        # Panel principal
â”‚   â”‚   â”‚   â”œâ”€â”€ SystemsPage.tsx          # AI Systems DB
â”‚   â”‚   â”‚   â”œâ”€â”€ GraphView.tsx            # AI Knowledge Graph 3D
â”‚   â”‚   â”‚   â”œâ”€â”€ ReasoningPage.tsx        # AI Symbolic Reasoning
â”‚   â”‚   â”‚   â”œâ”€â”€ ForensicAgentPage.tsx    # Forensic AI Agent
â”‚   â”‚   â”‚   â”œâ”€â”€ DPVPage.tsx              # DPV Browser
â”‚   â”‚   â”‚   â””â”€â”€ OntologyDocs.tsx         # DocumentaciÃ³n ontologÃ­a
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ Navbar.tsx
â”‚   â”‚   â””â”€â”€ lib/
â”œâ”€â”€ forensic_agent/            # Agente de AnÃ¡lisis Forense (8002)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ incident_extractor.py
â”‚   â”‚       â”œâ”€â”€ analysis_engine.py
â”‚   â”‚       â”œâ”€â”€ evidence_planner.py   # Evidence Planner (DPV)
â”‚   â”‚       â”œâ”€â”€ persistence.py
â”‚   â”‚       â””â”€â”€ mcp_client.py
â”œâ”€â”€ mcp-servers/               # Servidores MCP
â”‚   â””â”€â”€ forensic-sparql/
â”‚       â””â”€â”€ server.py
â”œâ”€â”€ reasoner_service/          # Microservicio de razonamiento SWRL (8001)
â”œâ”€â”€ ontologias/                # Archivos de ontologÃ­a
â”‚   â”œâ”€â”€ versions/0.37.4/
â”‚   â”œâ”€â”€ rules/
â”‚   â”œâ”€â”€ shacl/
â”‚   â””â”€â”€ mappings/
â”‚       â”œâ”€â”€ iso-42001-mappings.ttl
â”‚       â”œâ”€â”€ nist-ai-rmf-mappings.ttl
â”‚       â””â”€â”€ dpv-integration.ttl      # DPV 2.2 integration
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## API Reference

### Sistemas

```http
GET    /systems              # Listar sistemas
POST   /systems              # Registrar sistema
GET    /systems/{urn}        # Obtener sistema
PUT    /systems/{urn}        # Actualizar sistema
DELETE /systems/{urn}        # Eliminar sistema
```

### Razonamiento

```http
POST   /reasoning/system/{id}  # Ejecutar razonamiento SWRL
GET    /reasoning/rules        # Obtener reglas SWRL
GET    /reasoning/status       # Estado del servicio
```

### AnÃ¡lisis Forense

```http
POST   /forensic/analyze                    # Analizar narrativa de incidente
POST   /forensic/analyze-with-evidence-plan # Analizar + generar plan de evidencias
POST   /forensic/evidence-plan              # Generar plan de evidencias desde gaps
GET    /forensic/systems                    # Listar sistemas analizados
GET    /forensic/systems/{urn}              # Obtener anÃ¡lisis especÃ­fico
DELETE /forensic/systems/{urn}              # Eliminar anÃ¡lisis
```

### MCP Tools

```python
query_ontology(query)           # Ejecutar consultas SPARQL
get_requirements_for_system()   # Obtener requisitos EU AI Act
determine_risk_level()          # Determinar nivel de riesgo
query_iso_mappings()            # Consultar mappings ISO 42001
query_nist_mappings()           # Consultar mappings NIST AI RMF
get_inference_rules()           # Obtener reglas de inferencia
get_ontology_stats()            # EstadÃ­sticas de la ontologÃ­a
```

---

## Referencias

- **EU AI Act:** https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32024R1689
- **W3C Data Privacy Vocabulary (DPV) 2.2:** https://w3c.github.io/dpv/
- **AIAAIC Repository:** https://www.aiaaic.org/aiaaic-repository
- **AIRO (AI Risk Ontology):** https://w3id.org/airo
- **ISO/IEC 42001:2023:** https://www.iso.org/standard/81230.html
- **NIST AI RMF 1.0:** https://www.nist.gov/itl/ai-risk-management-framework
- **Apache Jena Fuseki:** https://jena.apache.org/documentation/fuseki2/
- **OWL 2 Web Ontology Language:** https://www.w3.org/TR/owl2-overview/
- **SHACL:** https://www.w3.org/TR/shacl/

---

## Licencia

Este proyecto utiliza la ontologÃ­a EU AI Act licenciada bajo **Creative Commons Attribution 4.0 International (CC BY 4.0)**.

El cÃ³digo fuente estÃ¡ disponible bajo los tÃ©rminos definidos por UNIR para Trabajos Fin de MÃ¡ster.

---

<p align="center">
  <img src="docs/logo-unir.png" alt="UNIR" width="150"/>
</p>

<p align="center">
  <strong>Universidad Internacional de La Rioja</strong><br/>
  MÃ¡ster en Inteligencia Artificial<br/>
  Curso 2024-2025
</p>

<p align="center">
  <sub>VersiÃ³n 1.1.0 | Diciembre 2025</sub>
</p>
