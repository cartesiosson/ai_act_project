# üß† AI Act SWRL Reasoner Service

## Descripci√≥n General

Este servicio implementa un **motor de razonamiento sem√°ntico h√≠brido** que combina **RDFLib** para el parsing de ontolog√≠as con **inferencia manual de reglas SWRL** para evaluar el cumplimiento del EU AI Act en sistemas de inteligencia artificial.

## üéØ Arquitectura del Reasoner

### Componentes Principales

1. **Parser RDFLib**: Carga y procesa archivos TTL (ontolog√≠as + datos del sistema)
2. **Motor SWRL Manual**: Aplica reglas de inferencia basadas en el EU AI Act
3. **Generador de Inferencias**: Produce nuevos triples RDF basados en las reglas
4. **Serializador**: Convierte el grafo resultante a TTL y JSON estructurado

### Flujo de Procesamiento

```mermaid
graph LR
    A[Sistema IA] --> B[Generaci√≥n TTL]
    B --> C[Carga Ontolog√≠a Base]
    C --> D[Aplicaci√≥n Reglas SWRL]
    D --> E[Inferencias Generadas]
    E --> F[Respuesta JSON + TTL]
```

## üìã Reglas SWRL Implementadas

### 1. **Reglas por Prop√≥sito (Purpose-based Rules)**

#### 1.1 Regla de Protecci√≥n Educativa
```swrl
hasPurpose(system, EducationAccess) ‚Üí hasNormativeCriterion(system, ProtectionOfMinors)
```
**Justificaci√≥n**: Anexo III, punto 3 del EU AI Act - Sistemas de evaluaci√≥n educativa requieren protecci√≥n especial de menores.

**Implementaci√≥n**:
```python
if (system, AI.hasPurpose, AI.EducationAccess) in combined_graph:
    combined_graph.add((system, AI.hasNormativeCriterion, AI.ProtectionOfMinors))
```

#### 1.2 Regla de No Discriminaci√≥n en Empleo
```swrl
hasPurpose(system, Employment) ‚Üí hasNormativeCriterion(system, NonDiscrimination)
```
**Justificaci√≥n**: Anexo III, punto 4 del EU AI Act - Sistemas de reclutamiento y empleo deben prevenir discriminaci√≥n.

#### 1.3 Regla de Seguridad Biom√©trica
```swrl
hasPurpose(system, BiometricIdentification) ‚Üí hasContextualCriterion(system, BiometricSecurity)
```
**Justificaci√≥n**: Anexo III, punto 1 del EU AI Act - Identificaci√≥n biom√©trica requiere medidas de seguridad espec√≠ficas.

### 2. **Reglas por Contexto de Despliegue (Context-based Rules)**

#### 2.1 Regla de Contexto Educativo
```swrl
hasDeploymentContext(system, Education) ‚Üí hasNormativeCriterion(system, ProtectionOfMinors)
```
**Justificaci√≥n**: Cualquier sistema desplegado en entorno educativo requiere protecci√≥n de menores independientemente del prop√≥sito.

#### 2.2 Regla de Servicios de Salud
```swrl
hasDeploymentContext(system, Healthcare) ‚Üí hasNormativeCriterion(system, EssentialServicesAccessCriterion)
```
**Justificaci√≥n**: Sistemas en entornos sanitarios afectan el acceso a servicios esenciales.

#### 2.3 Regla de Servicios P√∫blicos
```swrl
hasDeploymentContext(system, PublicServices) ‚Üí hasNormativeCriterion(system, EssentialServicesAccessCriterion)
```
**Justificaci√≥n**: Sistemas en servicios p√∫blicos pueden limitar el acceso ciudadano a servicios fundamentales.

#### 2.4 Regla de Procesamiento en Tiempo Real
```swrl
hasDeploymentContext(system, RealTimeProcessing) ‚Üí hasTechnicalCriterion(system, PerformanceRequirements)
```
**Justificaci√≥n**: Sistemas de tiempo real requieren garant√≠as de rendimiento espec√≠ficas.

#### 2.5 Regla de Alto Volumen
```swrl
hasDeploymentContext(system, HighVolumeProcessing) ‚Üí hasTechnicalCriterion(system, ScalabilityRequirements)
```
**Justificaci√≥n**: Sistemas de alto volumen necesitan requisitos de escalabilidad.

### 3. **Reglas en Cadena (Chain Rules)**

#### 3.1 Cadena de Protecci√≥n de Menores
```swrl
hasNormativeCriterion(system, ProtectionOfMinors) ‚Üí hasRequirement(system, ParentalConsent)
```
**Justificaci√≥n**: Art√≠culo 29 del EU AI Act - Protecci√≥n de menores requiere consentimiento parental.

#### 3.2 Cadena de No Discriminaci√≥n
```swrl
hasNormativeCriterion(system, NonDiscrimination) ‚Üí hasRequirement(system, Auditability)
```
**Justificaci√≥n**: Sistemas anti-discriminaci√≥n deben ser auditables para verificar cumplimiento.

#### 3.3 Cadena de Seguridad Biom√©trica
```swrl
hasContextualCriterion(system, BiometricSecurity) ‚Üí hasTechnicalRequirement(system, DataEncryption)
```
**Justificaci√≥n**: Datos biom√©tricos requieren cifrado por su naturaleza sensible.

#### 3.4 Cadena de Servicios Esenciales
```swrl
hasNormativeCriterion(system, EssentialServicesAccessCriterion) ‚Üí
    hasRequirement(system, HumanOversightRequirement) ‚àß
    hasRequirement(system, DataGovernanceRequirement) ‚àß
    hasRequirement(system, FundamentalRightsAssessmentRequirement)
```
**Justificaci√≥n**: Servicios esenciales requieren supervisi√≥n humana, gobernanza de datos y evaluaci√≥n de derechos fundamentales.

### 4. **Reglas de Pr√°cticas Prohibidas (Art. 5)**

#### 4.1 Regla de Pr√°ctica Prohibida ‚Üí Criterio
```swrl
hasProhibitedPractice(system, ?practice) ‚Üí hasCriteria(system, ?practice)
```
**Justificaci√≥n**: Art√≠culo 5 del EU AI Act - Las pr√°cticas prohibidas se convierten en criterios activados para permitir la inferencia de nivel de riesgo.

#### 4.2 Regla de Criterio ‚Üí Nivel de Riesgo Inaceptable
```swrl
hasCriteria(system, ?criterion) ‚àß assignsRiskLevel(?criterion, ?riskLevel) ‚Üí hasRiskLevel(system, ?riskLevel)
```
**Justificaci√≥n**: Si un criterio (incluyendo pr√°cticas prohibidas) asigna un nivel de riesgo, el sistema hereda ese nivel. Las pr√°cticas prohibidas del Art. 5 asignan `UnacceptableRisk`.

#### 4.3 Regla de Override de Niveles de Riesgo (REGLA 5.5)
```swrl
hasRiskLevel(system, UnacceptableRisk) ‚Üí ¬¨hasRiskLevel(system, HighRisk) ‚àß ¬¨hasRiskLevel(system, LimitedRisk) ‚àß ¬¨hasRiskLevel(system, MinimalRisk)
```
**Justificaci√≥n**: Cuando un sistema tiene m√∫ltiples niveles de riesgo inferidos de diferentes criterios, el nivel m√°s restrictivo prevalece. La jerarqu√≠a es:
- **UnacceptableRisk** > HighRisk > LimitedRisk > MinimalRisk

**Comportamiento**:
- Si `UnacceptableRisk` est√° presente ‚Üí elimina `HighRisk`, `LimitedRisk`, `MinimalRisk`
- Si `HighRisk` est√° presente (sin Unacceptable) ‚Üí elimina `LimitedRisk`, `MinimalRisk`
- Si `LimitedRisk` est√° presente (sin High ni Unacceptable) ‚Üí elimina `MinimalRisk`

**Ejemplo**:
Un sistema con `BiometricIdentification` (infiere `HighRisk`) y `PredictivePolicingProfilingCriterion` (infiere `UnacceptableRisk`) solo mostrar√° `UnacceptableRisk` como nivel de riesgo final.

**Pr√°cticas prohibidas definidas (Art. 5):**
| Criterio | Art√≠culo | Nivel de Riesgo |
|----------|----------|-----------------|
| `ai:SubliminalManipulationCriterion` | Art. 5(1)(a) | UnacceptableRisk |
| `ai:VulnerabilityExploitationCriterion` | Art. 5(1)(b) | UnacceptableRisk |
| `ai:SocialScoringCriterion` | Art. 5(1)(c) | UnacceptableRisk |
| `ai:PredictivePolicingProfilingCriterion` | Art. 5(1)(d) | UnacceptableRisk |
| `ai:RealTimeBiometricIdentificationCriterion` | Art. 5(1)(h) | UnacceptableRisk |

**Implementaci√≥n**:
```python
# En backend/swrl_rules.py
ai:ProhibitedPracticeToCriteriaRule rdf:type swrl:Rule ;
    swrl:body [ hasProhibitedPractice(?system, ?practice) ] ;
    swrl:head [ hasCriteria(?system, ?practice) ] .

# La regla CriterionRiskLevelRule existente infiere:
ai:CriterionRiskLevelRule rdf:type swrl:Rule ;
    swrl:body [ hasCriteria(?system, ?criterion) ‚àß assignsRiskLevel(?criterion, ?riskLevel) ] ;
    swrl:head [ hasRiskLevel(?system, ?riskLevel) ] .
```

#### 4.4 Regla de Excepciones Art. 5.2 (REGLA 5.5a)
```swrl
hasProhibitedPractice(system, RealTimeBiometricIdentificationCriterion) ‚àß
hasLegalException(system, ?exception) ‚àß
hasJudicialAuthorization(system, true) ‚Üí
    ¬¨hasRiskLevel(system, UnacceptableRisk) ‚àß
    hasRiskLevel(system, HighRisk) ‚àß
    hasArticle5Exception(system, true)
```
**Justificaci√≥n**: Art√≠culo 5(2) del EU AI Act permite excepciones **√∫nicamente** para la identificaci√≥n biom√©trica remota en tiempo real cuando se cumplen **todas** las condiciones:
1. El sistema utiliza identificaci√≥n biom√©trica remota en tiempo real (Art. 5.1.h)
2. Existe una excepci√≥n legal v√°lida del Art. 5.2
3. Se ha obtenido autorizaci√≥n judicial previa

**Excepciones v√°lidas del Art. 5.2:**
| Excepci√≥n | Art√≠culo | Descripci√≥n |
|-----------|----------|-------------|
| `ai:VictimSearchException` | Art. 5.2(a) | B√∫squeda de v√≠ctimas de secuestro, trata de personas, explotaci√≥n sexual |
| `ai:TerroristThreatException` | Art. 5.2(b) | Prevenci√≥n de amenaza terrorista espec√≠fica e inminente |
| `ai:SeriousCrimeException` | Art. 5.2(c) | Localizaci√≥n/identificaci√≥n de sospechoso de delito grave (Anexo II) |

**Comportamiento**:
- Si el sistema cumple las 3 condiciones ‚Üí `UnacceptableRisk` se convierte en `HighRisk`
- El sistema puede desplegarse, pero sigue siendo de **alto riesgo** con todas las obligaciones del T√≠tulo III
- Se a√±ade `hasArticle5Exception: true` para indicar que opera bajo excepci√≥n

**IMPORTANTE**: Las dem√°s pr√°cticas prohibidas (manipulaci√≥n subliminal, explotaci√≥n de vulnerabilidades, social scoring, predictive policing) **NO tienen excepciones** y siempre resultan en `UnacceptableRisk`.

**Ejemplo**:
```ttl
<urn:uuid:system-biometric> a ai:IntelligentSystem ;
    ai:hasName "Sistema Policial de B√∫squeda" ;
    ai:hasProhibitedPractice ai:RealTimeBiometricIdentificationCriterion ;
    ai:hasLegalException ai:VictimSearchException ;
    ai:hasJudicialAuthorization true .

# Resultado del razonamiento:
# hasRiskLevel: HighRisk (no UnacceptableRisk)
# hasArticle5Exception: true
```

### 5. **Reglas de √Åmbito de Aplicaci√≥n (Art. 2)**

#### 5.1 Regla de Exclusi√≥n de Scope
```swrl
hasPurpose(system, ?purpose) ‚àß mayBeExcludedBy(?purpose, ?exclusion) ‚Üí
    hasPotentialScopeExclusion(system, ?exclusion)
```
**Justificaci√≥n**: Art√≠culo 2 del EU AI Act - Ciertos prop√≥sitos pueden estar excluidos del √°mbito de aplicaci√≥n.

#### 5.2 Regla de Override de Exclusi√≥n
```swrl
hasPotentialScopeExclusion(system, ?exclusion) ‚àß
hasDeploymentContext(system, ?context) ‚àß
overridesExclusion(?context, ?exclusion) ‚Üí
    isInEUAIActScope(system, true)
```
**Justificaci√≥n**: Contextos con impacto real (v√≠ctimas, consecuencias legales, derechos fundamentales) anulan las exclusiones y traen el sistema de vuelta al √°mbito del reglamento.

**Contextos Override definidos:**
- `ai:CausesRealWorldHarmContext` - Da√±o real a personas
- `ai:VictimImpactContext` - V√≠ctimas identificables
- `ai:AffectsFundamentalRightsContext` - Afecta derechos fundamentales
- `ai:LegalConsequencesContext` - Consecuencias legales
- `ai:MinorsAffectedContext` - Menores afectados

### 6. **Reglas de Incidentes Graves (Art. 3(49))**

#### 6.1 Regla de Clasificaci√≥n de Incidente Grave
```swrl
hasIncidentType(system, ?type) ‚àß SeriousIncident(?type) ‚Üí
    hasSeriousIncidentType(system, ?type)
```
**Justificaci√≥n**: Art√≠culo 3(49) del EU AI Act - Clasificaci√≥n de incidentes graves seg√∫n taxonom√≠a.

#### 6.2 Regla de Notificaci√≥n Obligatoria (Art. 73)
```swrl
hasSeriousIncidentType(system, ?type) ‚àß triggersArticle73(?type, true) ‚Üí
    requiresIncidentNotification(system, true) ‚àß
    notificationDeadlineDays(system, 15)
```
**Justificaci√≥n**: Art√≠culo 73 del EU AI Act - Incidentes graves requieren notificaci√≥n a la autoridad competente en 15 d√≠as.

**Tipos de incidente grave (Art. 3(49)):**
| Tipo | Art√≠culo | Trigger Art. 73 |
|------|----------|-----------------|
| `ai:DeathOrHealthHarm` | Art. 3(49)(a) | ‚úì |
| `ai:CriticalInfrastructureDisruption` | Art. 3(49)(b) | ‚úì |
| `ai:FundamentalRightsInfringement` | Art. 3(49)(c) | ‚úì |
| `ai:PropertyOrEnvironmentHarm` | Art. 3(49)(d) | ‚úì |

### 7. **Reglas de Affected Persons (Art. 86)**

#### 7.1 Regla de Explicabilidad
```swrl
hasSubject(system, ?person) ‚àß hasRiskLevel(system, HighRisk) ‚Üí
    requiresExplainability(system, true)
```
**Justificaci√≥n**: Art√≠culo 86 del EU AI Act - Sistemas de alto riesgo con personas afectadas requieren explicabilidad.

#### 7.2 Regla de FRIA para Grupos Vulnerables
```swrl
hasSubject(system, ?person) ‚àß VulnerableGroup(?person) ‚Üí
    requiresFundamentalRightsAssessment(system, true)
```
**Justificaci√≥n**: Art√≠culo 27 del EU AI Act - Sistemas que afectan a grupos vulnerables requieren evaluaci√≥n de impacto en derechos fundamentales (FRIA).

**Grupos vulnerables detectados:**
- Menores (Minor/Child)
- Personas mayores (Elderly)
- Personas con discapacidad (Disabled)
- Migrantes y solicitantes de asilo (Migrant/Asylum)

## üîß Modo de Evaluaci√≥n

### Endpoint Principal
```
POST http://localhost:8001/reason
```

### Estructura de Entrada
```json
{
    "system_ttl": "...",     // TTL del sistema a evaluar
    "rules_ttl": "..."       // Reglas SWRL en formato TTL
}
```

### Estructura de Salida
```json
{
    "system_id": "urn:uuid:...",
    "system_name": "Ejemplo_1",
    "reasoning_completed": true,
    "inferred_relationships": {
        "hasNormativeCriterion": ["http://ai-act.eu/ai#EssentialServicesAccessCriterion"],
        "hasTechnicalCriterion": [],
        "hasContextualCriterion": ["http://ai-act.eu/ai#BiometricSecurity"],
        "hasRequirement": [
            "http://ai-act.eu/ai#DataGovernanceRequirement",
            "http://ai-act.eu/ai#FundamentalRightsAssessmentRequirement",
            "http://ai-act.eu/ai#HumanOversightRequirement"
        ],
        "hasTechnicalRequirement": ["http://ai-act.eu/ai#DataEncryption"]
    },
    "raw_ttl": "..."  // Grafo completo con inferencias
}
```

## üß™ Casos de Prueba

### Caso 1: Sistema Educativo
**Input**:
```ttl
<urn:uuid:system1> a ai:IntelligentSystem ;
    ai:hasPurpose ai:EducationAccess ;
    ai:hasDeploymentContext ai:Education .
```

**Inferencias Esperadas**:
- `hasNormativeCriterion: ProtectionOfMinors` (por prop√≥sito + contexto)
- `hasRequirement: ParentalConsent` (regla en cadena)

### Caso 2: Sistema Biom√©trico en Servicios P√∫blicos
**Input**:
```ttl
<urn:uuid:system2> a ai:IntelligentSystem ;
    ai:hasPurpose ai:BiometricIdentification ;
    ai:hasDeploymentContext ai:PublicServices .
```

**Inferencias Esperadas**:
- `hasContextualCriterion: BiometricSecurity` (por prop√≥sito)
- `hasTechnicalRequirement: DataEncryption` (regla en cadena)
- `hasNormativeCriterion: EssentialServicesAccessCriterion` (por contexto)
- `hasRequirement: HumanOversightRequirement, DataGovernanceRequirement, FundamentalRightsAssessmentRequirement` (regla en cadena)

### Caso 3: Sistema con Incidente Grave (Art. 3(49))
**Input**:
```ttl
<urn:uuid:system3> a ai:IntelligentSystem ;
    ai:hasPurpose ai:LawEnforcementSupport ;
    ai:hasIncidentType ai:FundamentalRightsInfringement .
```

**Inferencias Esperadas**:
- `hasSeriousIncidentType: FundamentalRightsInfringement` (Art. 3(49)(c))
- `requiresIncidentNotification: true` (Art. 73)
- `notificationDeadlineDays: 15` (Art. 73)

### Caso 4: Sistema con Pr√°ctica Prohibida (Art. 5)
**Input**:
```ttl
<urn:uuid:system4> a ai:IntelligentSystem ;
    ai:hasName "Paco" ;
    ai:hasPurpose ai:BiometricIdentification ;
    ai:hasDeploymentContext ai:WorkplaceMonitoringContext ;
    ai:hasProhibitedPractice ai:PredictivePolicingProfilingCriterion .
```

**Inferencias Esperadas**:
- `hasCriteria: PredictivePolicingProfilingCriterion` (por regla ProhibitedPracticeToCriteriaRule)
- `hasRiskLevel: UnacceptableRisk` (por regla CriterionRiskLevelRule, ya que PredictivePolicingProfilingCriterion tiene assignsRiskLevel UnacceptableRisk)

**Nota**: Los sistemas con nivel de riesgo `UnacceptableRisk` no pueden desplegarse en la UE.

### Caso 5: Sistema Excluido con Override (Art. 2)
**Input**:
```ttl
<urn:uuid:system5> a ai:IntelligentSystem ;
    ai:hasPurpose ai:Entertainment ;
    ai:hasDeploymentContext ai:VictimImpactContext .
```

**Inferencias Esperadas**:
- `hasPotentialScopeExclusion: EntertainmentWithoutRightsImpact` (Art. 2)
- `isInEUAIActScope: true` (override por VictimImpactContext)
- `requiresFRIA: true` (Art. 27)

## üîç Debugging y Logs

### Activaci√≥n de Logs Detallados
Los logs est√°n habilitados por defecto y muestran:
```
DEBUG: Procesando sistema: urn:uuid:...
DEBUG: Verificando BiometricIdentification para urn:uuid:...
DEBUG: ¬øTiene prop√≥sito BiometricIdentification? True
DEBUG: ‚úÖ Inferencia aplicada: urn:uuid:... -> hasContextualCriterion -> BiometricSecurity (por prop√≥sito)
DEBUG: *** RAZONAMIENTO COMPLETADO: 6 inferencias aplicadas ***
```

### Verificaci√≥n de Reglas
Para verificar qu√© reglas se est√°n aplicando:
1. Revisar logs del container: `docker-compose logs reasoner`
2. Contar inferencias aplicadas en la respuesta
3. Validar coherencia con la ontolog√≠a base

## üöÄ Extensi√≥n del Sistema

### Agregar Nueva Regla SWRL

1. **Definir la regla** en `backend/swrl_rules.py`:
```ttl
ai:NewRule rdf:type swrl:Rule ;
    swrl:body [ /* condici√≥n */ ] ;
    swrl:head [ /* inferencia */ ] .
```

2. **Implementar l√≥gica** en `reasoner_service/app/main.py`:
```python
# NUEVA REGLA: Condici√≥n -> Inferencia
if (system, AI.hasProperty, AI.Value) in combined_graph:
    combined_graph.add((system, AI.hasNewProperty, AI.NewValue))
    print(f"DEBUG: ‚úÖ Inferencia aplicada: {system} -> hasNewProperty -> NewValue")
    inferences_count += 1
```

3. **Reconstruir container**:
```bash
docker-compose up -d --build reasoner
```

### Consideraciones de Rendimiento
- Las reglas se eval√∫an secuencialmente
- El grafo combinado se mantiene en memoria
- Para sistemas complejos, considerar optimizaci√≥n de consultas SPARQL

## üìö Referencias

- **EU AI Act**: Regulation (EU) 2024/1689
- **SWRL Specification**: https://www.w3.org/Submission/SWRL/
- **RDFLib Documentation**: https://rdflib.readthedocs.io/
- **Ontolog√≠a AI Act**: `/ontologias/versions/0.41.0/ontologia-v0.41.0.ttl`

## ü§ù Contribuci√≥n

Para contribuir nuevas reglas SWRL:
1. Identificar el art√≠culo/anexo del EU AI Act aplicable
2. Definir la regla en sintaxis SWRL formal
3. Implementar la l√≥gica de inferencia
4. Agregar casos de prueba
5. Documentar la justificaci√≥n legal

---

**Versi√≥n**: 1.3
**√öltima Actualizaci√≥n**: Enero 2026
**Compatibilidad**: EU AI Act Ontology v0.41.0

---

### Changelog

#### v1.3 (Enero 2026)
- Nueva regla 4.4 (REGLA 5.5a): Excepciones Art. 5.2 para identificaci√≥n biom√©trica remota
- Soporte para `hasLegalException` y `hasJudicialAuthorization` en TTL
- Sistemas con excepci√≥n v√°lida + autorizaci√≥n judicial pasan de UnacceptableRisk a HighRisk
- A√±adida propiedad `hasArticle5Exception` para indicar operaci√≥n bajo excepci√≥n
- Fix: Bug de cierre de conexi√≥n MongoDB en errores de duplicado

#### v1.2 (Enero 2026)
- Nueva regla 4.3 (REGLA 5.5): Override de niveles de riesgo - el m√°s restrictivo prevalece
- Jerarqu√≠a implementada: UnacceptableRisk > HighRisk > LimitedRisk > MinimalRisk
- Fix: Sistemas con m√∫ltiples criterios de riesgo ahora muestran solo el nivel m√°s alto

#### v1.1 (Enero 2026)
- A√±adida secci√≥n 4: Reglas de Pr√°cticas Prohibidas (Art. 5)
- Nueva regla `ProhibitedPracticeToCriteriaRule`: convierte pr√°cticas prohibidas en criterios
- Soporte para inferencia autom√°tica de `UnacceptableRisk` desde pr√°cticas prohibidas
- A√±adido Caso de Prueba 4: Sistema con pr√°ctica prohibida
- Renumeraci√≥n de secciones 5-7